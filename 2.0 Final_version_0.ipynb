{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91de21d6",
   "metadata": {},
   "source": [
    "# Base Model\n",
    "This base model has been created using a data set containing images in gray scale. Each image is framed just to the face, which expresion represents one of seven emotions (happy, sad, angry, fear, disgust, neutral and surprise). The number of images for the training set is 28,709 in the seven classes and the testing set contain 7,178 images in the seven classes.\n",
    "\n",
    "This is the first model created to train the data set. The idea is to look at the initial implementation and from there increase the number of layers and improve the parameters inputed. \n",
    "\n",
    "The first part is the architecture of this base model which is composed by the input layer, one hidden layer and the output layer. The class that will be used is Sequential from the Keras library to initialize the Convolutional Neural Network. Then for a convolution a Convolution2D is added where the parameters include the size of the images we are going to input, in this particular case 48x48 to gray scale, and the Activation will be the relu function. For the Pooling, MaxPooling2D will be used with a pool-size of 2x2 followed by Flattening with Flatten fuction. In addition to the Convolution layer which is the input layer, two Dense layers will be included. The first one is the hidden layer that will have 128 neurons and relu as activation function. The second Dense layer will be the output layer, which will have seven cathegories in this case (the dataset has seven emotions to gray scale) and the activation function that is softmax. With this, we finish all the connections needed for the Convolutional Neural Network.The following step is to compile the Convolutional Neural Network using adam as optimizer, cathegorical crossentropy for the loss, and accuracy for the metrics.\n",
    "\n",
    "The second part is fitting the Convolutional Neural Network to the images, but before it a ImageDataGenerator is included to generated more images through transformation of the orginals. This transformations include rescaling, shearing, zooming, and horizontal flipping all the original images to create more and train in a better way our Convolutional Neural Network. Posteriously, the train and test set will be loaded including the path to each of the folders, the target espected size that images should have, the batch step which is 32, the color that in this case must be included that is gray scale, and categorical as class mode. Finally, the fitting step where the training set is include, the number of epochs is initialized with 30, the validation data which is the test set and the verbose input to 1 to see how the accuracy and loss are improve with epoch.\n",
    "\n",
    "The table of content for this file is as follow:\n",
    "   #### 2.1   Packages and Libraries\n",
    "   #### 2.2   Initialize the Convolutional Neural Network\n",
    "   #### 2.3   Convolution\n",
    "   #### 2.4   Pooling\n",
    "   #### 2.5   Flattening\n",
    "   #### 2.6   Full Conection\n",
    "   #### 2.7   Compiling the Convolutional Neural Network\n",
    "   #### 2.8   Model Summary\n",
    "   #### 2.9   Generating More Images\n",
    "   #### 2.10 Fitting the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3c985",
   "metadata": {},
   "source": [
    "## 2.1 Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8beb04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This are all the packages and libraries that will be\n",
    "#used for the Convolutional Neural Network\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefaa41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e094fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (48, 48) maximum color level 0.94509804\n",
      "image shape (48, 48) maximum color level 0.9490196\n",
      "image shape (48, 48) maximum color level 0.9411765\n",
      "image shape (48, 48) maximum color level 0.9137255\n",
      "image shape (48, 48) maximum color level 0.93333334\n",
      "image shape (48, 48) maximum color level 0.92941177\n",
      "image shape (48, 48) maximum color level 0.9254902\n",
      "image shape (48, 48) maximum color level 0.8745098\n",
      "image shape (48, 48) maximum color level 0.92941177\n",
      "image shape (48, 48) maximum color level 1.0\n"
     ]
    }
   ],
   "source": [
    "# Exploring shape and color level for some of the images\n",
    "#in the test set for the happy emotion\n",
    "images = []\n",
    "for i in range(10):\n",
    "    im = img.imread(r'feelings\\test\\happy\\im{}.png'.format(i))\n",
    "    images.append(im)\n",
    "    print('image shape', im.shape, 'maximum color level', im.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc148af5",
   "metadata": {},
   "source": [
    "Noticing that images are size 48 by 48 which is an important parameter for the input layer in the Convolutional Neural Network. Also, the maximum color level is always below or equal to 1 and this happen because our dataset is composed by gray scale images. In case the images are colorful, the maximum value will be between zero and three."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b81ca",
   "metadata": {},
   "source": [
    "## 2.2 Initializing the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f66dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5b215",
   "metadata": {},
   "source": [
    "## 2.3 Convolution\n",
    "Inside of the initialization of a Convolutional Neural Network breaking step down can be done to understand the process that is followed. In this case, convolution is the first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf344720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3 ,3, \n",
    "                             input_shape = (48, 48, 1), \n",
    "                             activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9302b49",
   "metadata": {},
   "source": [
    "## 2.4 Pooling\n",
    "This is the second step in the initializing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299354c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975920c",
   "metadata": {},
   "source": [
    "## 2.5 Flattening\n",
    "Third step in the initializing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "167fee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98105169",
   "metadata": {},
   "source": [
    "## 2.6 Full Connection\n",
    "In this fourth step, we create the hidden and output layer to create a full connection with the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c195ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 - Full Connection\n",
    "classifier.add(Dense(128, activation = 'relu'))\n",
    "classifier.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d6226",
   "metadata": {},
   "source": [
    "## 2.7 Compiling the Convolutional Neural Network\n",
    "Final part of the initializing process and the model is ready for the second part which is the fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72e946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss= 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2d34c",
   "metadata": {},
   "source": [
    "## 2.8 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588ea35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 263,495\n",
      "Trainable params: 263,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#A summary of the model is printed to review the different\n",
    "#outputs after each layer\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb2162",
   "metadata": {},
   "source": [
    "In the summary appears the type of model used (Sequential), the  names of the different steps and their respective output shape. It is noticeable that the conv2d is the input layer and the output shape of the images will be 16 by 16, given a total of 320 parameters.\n",
    "In the pooling the images are reduced by half again and there are not parameters agregated. Same for the flatten layer, there are not parameters agregated. Followed by one Dense layer this is the hidden layer which contain 128*2048=262272 parameters. At the end, the Dense layer dense_1 is the output layer with a total number of parameters of 903. The total number of parameters is 320+262272+903=263495 which is low because the number of hidden layer is one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf5b14",
   "metadata": {},
   "source": [
    "## 2.9 Generating More Images\n",
    "The idea is to create more images from the ones in the training test by making transformation such as rescaling, shearing, zooming and flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e32a36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#Part 2 - Fitting the CNN to the images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'feelings/train',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'feelings/test',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8b832",
   "metadata": {},
   "source": [
    "## 2.10 Fitting the Convolutional Neural Network\n",
    "In this step, parameters are imputed such as the training set, epoch to thirty, testing set, and vebose to one looking for information related to the time for epoch, loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history variable contains information from the fitting that\n",
    "#can help to plot loss and accuracy graphs\n",
    "history = classifier.fit(\n",
    "    training_set,\n",
    "    epochs=30,\n",
    "    validation_data=test_set,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b8608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
