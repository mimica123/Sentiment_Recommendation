{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0d09ea",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "Now that a base model has been trained, it is time to include more layers to the model. This step will help to improve the learning process of the Convolutional Neural Network. First of all, BatchNormalization and Dropout are included after each layer. Dropout will help to prevent overfitting and BatchNormalization provides normalization effect which speed the learning process of the Convolutional Neural Network. In addition to the initial three layers in the base model (input, hiden and output layer), four more layers have been added. Three with 512 neurons and one with 256 neurons applying BatchNormalization, MaxPool2D and Dropout after each of them to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be357d69",
   "metadata": {},
   "source": [
    "# 4.1 Importing Libraries\n",
    "Same libraries and packages used in the base model are used in this case, but including BatchNormalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30c849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D,Dropout,BatchNormalization\n",
    "from tensorflow.python.keras import regularizers\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea9564",
   "metadata": {},
   "source": [
    "# 4.2 Layers for the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39cc2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,3)))\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916929a",
   "metadata": {},
   "source": [
    "# 4.3 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ae0a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,495,940\n",
      "Trainable params: 4,491,972\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a195e",
   "metadata": {},
   "source": [
    "With the inclusion of the four layers the number of parameters augmented to 4,495,940 which will help to improve the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723a192",
   "metadata": {},
   "source": [
    "# 4.4 Fitting the Model\n",
    "This time the number of epochs is 150 compared with 60 in the base model for the gray and color scale dataset trained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492e5c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4001 images belonging to 5 classes.\n",
      "Found 947 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Part 2 - Fitting the CNN to the images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'feelings/Clean1/train',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'feelings/Clean1/test',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    epochs=150,\n",
    "    validation_data=test_set,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3860d3",
   "metadata": {},
   "source": [
    "# 4.5 Saving Weights\n",
    "One important step for model that need long time to train is to save the weights from the Convolutional Neural Network. The reason for this is that will permit us to continuous training our model or to use the model with  more layers on top of the ones used in the training process. At the same time, it will help to avoid training from the beginning in case a future result based in the model is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dec46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For saving the weights\n",
    "model.save_weights(\"my_model_weights2.180.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
